{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f1f3833-fe88-4ff7-a4b0-29aacf584d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models, layers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65c84b13-78f4-4d91-a37b-222170aa1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "497189bf-592d-47df-99d0-4719299c6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_shape_check(image_dir):\n",
    "    \n",
    "    print('Generating Paths')\n",
    "    image_paths = []\n",
    "    for image in os.listdir(image_dir):\n",
    "        if image.endswith('.png'):\n",
    "            image_paths.append(os.path.join(image_dir, image))\n",
    "    \n",
    "    print('Checking Shapes')\n",
    "    image_shapes = []\n",
    "    for image in image_paths:\n",
    "        np_image = imread(image)\n",
    "        image_shapes.append(np_image.shape)\n",
    "    \n",
    "    print(f'Shapes found: {list(set(image_shapes))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c666326c-508b-4919-aa9c-6c9ae7c27f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Paths\n",
      "Checking Shapes\n",
      "Shapes found: [(600, 800, 4)]\n"
     ]
    }
   ],
   "source": [
    "image_shape_check(\"/home/jupyter/data_image/legit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2b2eb-8b48-46b4-a5d6-7af1775bd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Paths\n",
      "Checking Shapes\n"
     ]
    }
   ],
   "source": [
    "image_shape_check(\"/home/jupyter/data_image/scam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34541947-a249-4737-ac71-4faf50ba6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.keras.utils.image_dataset_from_directory(\"/home/jupyter/data_image/\", image_size=(300, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d52c130-d3d3-4686-a1dd-17e890d2ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    rel_path = '/home/jupyter/data_image/'\n",
    "    legit_dir_path = os.path.join(rel_path, 'legit')\n",
    "    scam_dir_path = os.path.join(rel_path, 'scam')\n",
    "    \n",
    "    # Legit paths\n",
    "    legit_image_paths = []\n",
    "    for im_file in os.listdir(legit_dir_path):\n",
    "        if im_file.endswith('.png'):\n",
    "            legit_image_paths.append(os.path.join(legit_dir_path, im_file))\n",
    "    \n",
    "    # Scam paths\n",
    "    scam_image_paths = []\n",
    "    for im_file in os.listdir(scam_dir_path):\n",
    "        if im_file.endswith('.png'):\n",
    "            scam_image_paths.append(os.path.join(scam_dir_path, im_file))\n",
    "    \n",
    "    X, y = [], []\n",
    "    print('Importing legit images')\n",
    "    for legit_image in legit_image_paths:\n",
    "        np_legit_image = imread(legit_image)[:, :, :3] # slice off the alpha channel\n",
    "        resized_image = tf.image.resize(np_legit_image, (300, 400))\n",
    "        X.append(resized_image)\n",
    "        y.append(0)\n",
    "    \n",
    "    print('Importing scam images')\n",
    "    for scam_image in scam_image_paths:\n",
    "        np_scam_image = imread(scam_image)[:, :, :3] # slice off the alpha channel\n",
    "        resized_image = tf.image.resize(np_scam_image, (300, 400))\n",
    "        X.append(resized_image)\n",
    "        y.append(1)\n",
    "    \n",
    "    print('Finished importing')\n",
    "    \n",
    "    print('\\nShuffling Data')\n",
    "    c = list(zip(X, y))\n",
    "    np.random.shuffle(c)\n",
    "    X, y = zip(*c)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf5aca-72c1-4032-8df1-70adf615cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e2661-431d-4010-902e-78d836379323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shape = ds._structure[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab38bb96-78c7-4fa6-90c9-1b273be03908",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() takes from 1 to 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5011/111301844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: array() takes from 1 to 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "X = np.array(1, 300, 400, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee68c3-0083-4e81-a5e8-af0e72f9ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tfdf_clean = df[['Target','clean_text']]\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069c1e54-b641-4720-b9f1-a08d51551664",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = pd.read_csv(\"/home/jupyter/data_urls/legit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb98dde-912d-4350-a5be-cfd79e1def9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>num_of_picture</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.theaccessbankukltd.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>menuaboutpersonalbusinessprivatedubainewsconta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.adambank.com</td>\n",
       "      <td>1</td>\n",
       "      <td>transfer contact usloginon 3 september 2022 we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.adib.co.uk</td>\n",
       "      <td>2</td>\n",
       "      <td>sign inâ€‹homeabout adibour brandmission   objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.aldermore.co.uk</td>\n",
       "      <td>3</td>\n",
       "      <td>log inpersonalbusinessintermediariesabout usco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>http://www.allfunds.com/en</td>\n",
       "      <td>4</td>\n",
       "      <td>cookie configurationallfunds bank s a u   allf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>2184</td>\n",
       "      <td>2219</td>\n",
       "      <td>http://www.roberthalf.com/</td>\n",
       "      <td>2104</td>\n",
       "      <td>this website uses cookies to improve user expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>2185</td>\n",
       "      <td>2220</td>\n",
       "      <td>http://www.compass-group.com/</td>\n",
       "      <td>2105</td>\n",
       "      <td>our use of cookieswe use necessary cookies to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2186</td>\n",
       "      <td>2221</td>\n",
       "      <td>http://shop.hasbro.com/</td>\n",
       "      <td>2106</td>\n",
       "      <td>skip to main contentnl   nederlandsontdek spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2187</td>\n",
       "      <td>2222</td>\n",
       "      <td>http://www.ropertech.com/</td>\n",
       "      <td>2107</td>\n",
       "      <td>skip to contentâ†µenterskip to contentsimple ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2188</td>\n",
       "      <td>2223</td>\n",
       "      <td>http://www.arkocorp.com/</td>\n",
       "      <td>2108</td>\n",
       "      <td>investorsoverviewnews   eventsoverviewpress re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2189 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index                                  url  num_of_picture  \\\n",
       "0              0      0  http://www.theaccessbankukltd.co.uk               0   \n",
       "1              1      1              http://www.adambank.com               1   \n",
       "2              2      2                http://www.adib.co.uk               2   \n",
       "3              3      3           http://www.aldermore.co.uk               3   \n",
       "4              4      4           http://www.allfunds.com/en               4   \n",
       "...          ...    ...                                  ...             ...   \n",
       "2184        2184   2219           http://www.roberthalf.com/            2104   \n",
       "2185        2185   2220        http://www.compass-group.com/            2105   \n",
       "2186        2186   2221              http://shop.hasbro.com/            2106   \n",
       "2187        2187   2222            http://www.ropertech.com/            2107   \n",
       "2188        2188   2223             http://www.arkocorp.com/            2108   \n",
       "\n",
       "                                                   text  \n",
       "0     menuaboutpersonalbusinessprivatedubainewsconta...  \n",
       "1     transfer contact usloginon 3 september 2022 we...  \n",
       "2     sign inâ€‹homeabout adibour brandmission   objec...  \n",
       "3     log inpersonalbusinessintermediariesabout usco...  \n",
       "4     cookie configurationallfunds bank s a u   allf...  \n",
       "...                                                 ...  \n",
       "2184  this website uses cookies to improve user expe...  \n",
       "2185  our use of cookieswe use necessary cookies to ...  \n",
       "2186  skip to main contentnl   nederlandsontdek spee...  \n",
       "2187  skip to contentâ†µenterskip to contentsimple ide...  \n",
       "2188  investorsoverviewnews   eventsoverviewpress re...  \n",
       "\n",
       "[2189 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afbe5a6-37fd-4fd4-a6de-72c09f8fd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db76ad7b-a0e7-4482-8a43-109764310484",
   "metadata": {},
   "outputs": [],
   "source": [
    "scam = pd.read_csv(\"/home/jupyter/data_urls/scam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7138ab0-537e-4761-9b91-9abe4218cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scam.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e74068c-ff36-480c-8884-5a0322a23b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scam['Target'] = 1\n",
    "legit['Target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b12a7b6-10c1-4a38-9dce-d2205401022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([scam, legit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67266140-c732-4303-9b31-7508bc0107b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk import word_tokenize \n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de850838-119a-4a53-b883-e7affde9290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.split()\n",
    "    words_only = [word for word in text if word.isalpha()]\n",
    "    for punctuation in string.punctuation:\n",
    "        words_only = [word.replace(punctuation, ' ').lower() for word in words_only] # Remove Punctuation\n",
    "    # lowercased = text.lower() # Lower Case\n",
    "    #tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    # words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    # lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    # lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa43eb02-7062-477f-91db-36fe6ab20973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['str_text'] = df['text'].astype('str')\n",
    "df['clean_text'] = df['str_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "067b2a9f-f7c3-4ed1-8c5d-b0c7f6579d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[['Target','clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e53e696-8867-4629-b65b-3145ec9e00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce53a564-831a-4dd5-b477-e7f1ab94162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95a4563-2db8-43ef-be92-2c4040c4aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30caa52e-26d9-466a-baeb-04d8c3c895d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "040cef27-cf1b-43b9-93d7-c6a4596e1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_transfer = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "752d04eb-19e8-4422-9461-479ad7d897ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text, y_text = df_clean['clean_text'], df_clean['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a971845-10f3-485c-9a2e-c9a89bef7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_embed = embedding(word2vec_transfer, X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9113447-640e-4961-abb7-61bed5ee9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad = pad_sequences(X_text_embed, dtype='float32', padding='post', maxlen=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c13b8fb-6493-4167-a42e-2835f02e6468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4223, 200, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00cb78-4929-4a7d-9274-9acaebb7681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=tf.keras.Input(shape = X_shape[1:])\n",
    "x = layers.Conv2D(16, (4, 4))(input1)\n",
    "x = layers.MaxPool2D(2, 2)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(16, (4, 4), activation='relu')(x)\n",
    "x = layers.MaxPool2D(2, 2)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(16, (4, 4), activation='relu')(x)\n",
    "x = layers.MaxPool2D(2, 2)(x)\n",
    "# x = layers.BatchNormalization(x)\n",
    "\n",
    "cnn_out = layers.Flatten()(x)\n",
    "\n",
    "input2 = layers.Input(shape=(X_pad.shape))\n",
    "y = layers.Masking()(input2)\n",
    "# y = layers.BatchNormalization()(input2)\n",
    "y = layers.LSTM(30, activation='tanh', return_sequences=True)(y)\n",
    "y = layers.LSTM(20, activation='tanh', return_sequences=True)(y)\n",
    "nlp_out = layers.LSTM(10, activation='tanh')(y)\n",
    "\n",
    "concat = layers.concatenate([cnn_out, nlp_out])\n",
    "\n",
    "z = layers.Dense(64, activation='relu')(concat)\n",
    "z = layers.Dense(32, activation='relu')(z)\n",
    "\n",
    "output  = layers.Dense(1, activation='sigmoid')(z)                     \n",
    "# add layers here to process input 1 as you wish \n",
    "# last layer should be a Flatten layer or GlobalMaxPooling Layer\n",
    "\n",
    "model=keras.Model(inputs=[input1,input2], outputs=output)\n",
    "#  then compile your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "844fe44e-6ace-46e4-a177-c4a051e073cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 300, 400, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 297, 397, 16  784         ['input_17[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 148, 198, 16  0          ['conv2d_30[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 145, 195, 16  4112        ['max_pooling2d_30[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 200, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 72, 97, 16)  0           ['conv2d_31[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " masking_8 (Masking)            (None, 200, 1)       0           ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 69, 94, 16)   4112        ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, 200, 30)      3840        ['masking_8[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 34, 47, 16)  0           ['conv2d_32[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 200, 20)      4080        ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 25568)        0           ['max_pooling2d_32[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 10)           1240        ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 25578)        0           ['flatten_8[0][0]',              \n",
      "                                                                  'lstm_13[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           1637056     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           2080        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            33          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,657,337\n",
      "Trainable params: 1,657,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "400c52a0-35c9-4a82-b95d-aed325ba8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec0861c2-2f43-4a4b-844b-730443c63ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24062b44-c7a4-4470-a21d-096774589986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681c3a9-5bc0-4406-b3de-4174b33c2a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m100"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
