{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3346f433-04e7-4550-aa04-37cfbd9d936b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4b637c-e6b3-49f9-b0dd-83a95813b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 00:02:38.526377: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 00:02:38.526394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import tensorflow.image as tf_image\n",
    "from tensorflow.keras import layers, models, callbacks, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7730bd-880e-4d70-a73c-d7d3e10e3e76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_232468/3264347475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk import word_tokenize \n",
    "# import nltk\n",
    "from gensim.models import Word2Vec\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as api\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2bd3b-c0c4-4ec7-a5c4-4f35b8d00364",
   "metadata": {},
   "source": [
    "# Paths and key frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f87c8-b317-42ab-b1de-21338d7975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "rel_imagedir_path = '../../../data/screenshots/'\n",
    "legit_image_path = os.path.join(rel_imagedir_path, 'legit_screenshots')\n",
    "scam_image_path = os.path.join(rel_imagedir_path, 'scam_screenshots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec97193-5158-42d3-a573-c7be2a7d6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_image_path, scam_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee92c5-0b2a-4cdd-a795-048d10a30807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legit websites\n",
    "\n",
    "legit_key_df = pd.read_csv('legim_text_screenshots_key.csv')\n",
    "print(legit_key_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aab9a3-f34c-483b-b7ed-52584f26b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_key_df = legit_key_df.drop(columns=['Unnamed: 0', 'index'])\n",
    "legit_key_df['target'] = 0\n",
    "legit_key_df = legit_key_df.drop_duplicates(subset='url')\n",
    "legit_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fddd7c-2116-4c0f-b4ca-d5df8e12da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scam websites\n",
    "\n",
    "scam_key_df = pd.read_csv('scam_text_screenshots_key.csv')\n",
    "scam_key_df = scam_key_df.drop(columns=['Unnamed: 0'])\n",
    "scam_key_df['target'] = 1\n",
    "scam_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebafb81-026a-4056-bb20-b37ffdcd5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_key_df = pd.concat([legit_key_df, scam_key_df], ignore_index=True).reset_index(drop=True)\n",
    "merged_key_df = merged_key_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d47f9f-e72a-4a89-8a20-1f2e197e55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_key_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87edcf5f-6dde-4002-8a47-194c6ed4e971",
   "metadata": {},
   "source": [
    "# Checking image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcd2cc-a601-4922-a2e0-20d78ce00f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_shape_check(image_dir):\n",
    "    \n",
    "    print('Generating Paths')\n",
    "    image_paths = []\n",
    "    for image in os.listdir(image_dir):\n",
    "        if image.endswith('.png'):\n",
    "            # print(image)\n",
    "            image_paths.append(os.path.join(image_dir, image))\n",
    "    # print(image_paths)\n",
    "    \n",
    "    print('Checking Shapes')\n",
    "    image_shapes = []\n",
    "    for image in image_paths:\n",
    "        np_image = imread(image)\n",
    "        image_shapes.append(np_image.shape)\n",
    "    \n",
    "    print(f'Shapes found: {list(set(image_shapes))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5265f7d-e6d3-4bb9-83d8-8a98dd90a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a while to run and will use a lot of memory\n",
    "# image_shape_check(legit_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053107b5-e460-4d0a-88c9-e1a2f5a67268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a while to run and will use a lot of memory\n",
    "# image_shape_check(scam_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32854fe-40a9-4f29-9a90-91554eb7ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pillow_check(path_, img='3.png'):\n",
    "#     image = Image.open(os.path.join(path_, img))\n",
    "#     print(f'Image format: {image.format}')\n",
    "#     print(f'Image size: {image.size}')\n",
    "#     print(f'Image channels: {image.mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6eaf5-af77-44d2-802e-931e59415f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pillow_check(legit_image_path, '5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53d36f-ee7e-41ec-af01-ca312abca925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pillow_check(scam_image_path, '5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e682583-386b-4add-ac33-0ae9cd1e784c",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d1371-f1a5-498d-936f-c1d7234ead13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(key_df, legit_imagedir_path, scam_imagedir_path):\n",
    "    \n",
    "    X_image = []\n",
    "    X_text = []\n",
    "    y = []\n",
    "    \n",
    "    for index, row in key_df.iterrows():\n",
    "        if index % 500 == 0:\n",
    "            print(f'loaded {index} data points')\n",
    "        \n",
    "        # Append image to X_image\n",
    "        if row['target'] == 0:\n",
    "            image_path = os.path.join(legit_imagedir_path, f\"{row['num_of_picture']}.png\")\n",
    "            np_legit_image = imread(image_path)[:, :, :3] # slice off the alpha channel\n",
    "            np_legit_image = tf_image.resize(np_legit_image, (300, 400))\n",
    "            X_image.append(np_legit_image)\n",
    "            \n",
    "        elif row['target'] == 1:\n",
    "            image_path = os.path.join(scam_imagedir_path, f\"{row['num_of_picture']}.png\")\n",
    "            np_legit_image = imread(image_path)[:, :, :3] # slice off the alpha channel\n",
    "            np_legit_image = tf_image.resize(np_legit_image, (300, 400))\n",
    "            X_image.append(np_legit_image)\n",
    "        \n",
    "        # Load text\n",
    "        X_text.append(row['text'])\n",
    "        \n",
    "        y.append(row['target'])\n",
    "    \n",
    "    print('\\nFinished loading data!')\n",
    "    # print(X_image)\n",
    "    return np.array(X_image), X_text, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02620c5d-b6db-4c6c-9d89-392b095934dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a87e1-031a-422e-a60f-169c524bce11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_image, X_text, y = load_data(merged_key_df, legit_image_path, scam_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212d8d44-f75c-4dc3-b356-a6cb0aaf1134",
   "metadata": {},
   "source": [
    "# Proproccess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10d88a-13c2-4fe5-bf44-52faa511fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def clean(text):\n",
    "    text = text.split()\n",
    "    words_only = [word for word in text if word.isalpha()]\n",
    "    for punctuation in string.punctuation:\n",
    "        words_only = [word.replace(punctuation, ' ').lower() for word in words_only] # Remove Punctuation\n",
    "    # lowercased = text.lower() # Lower Case\n",
    "    #tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    # words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    # lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    # lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return without_stopwords\n",
    "\n",
    "def text_cleaner(list_text):\n",
    "    print('Cleaning text')\n",
    "    list_clean_text=[]\n",
    "    for text in list_text:\n",
    "        clean_txt=clean(text) # Use clean function\n",
    "        list_clean_text.append(clean_txt)\n",
    "\n",
    "    return list_clean_text\n",
    "\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return embedded_sentence\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    print('Embedding with word2vec')\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "def preprocess_pad(list_text):\n",
    "    # Clean - remove punctuation and stopwords\n",
    "    list_ = text_cleaner(list_text)\n",
    "    \n",
    "    # Embed with word2vec\n",
    "    word2vec_transfer = api.load('glove-wiki-gigaword-100')\n",
    "    list_ = embedding(word2vec_transfer, list_)\n",
    "    \n",
    "    # Pad Sequences\n",
    "    print('Padding sequences')\n",
    "    list_ = pad_sequences(list_, dtype='float32', padding='post', maxlen=200)\n",
    "    \n",
    "    print('Text preprocessing and embedding complete!')\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cfb20-b12a-461d-81ad-12154aa3788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_pad(list_text):\n",
    "#     df_clean=text_cleaner(X_text)\n",
    "#     df_clean.reset_index(drop = True, inplace=True)\n",
    "#     word2vec_transfer = api.load('glove-wiki-gigaword-100')\n",
    "#     X_train_embed_2 = embedding(word2vec_transfer, df_clean['clean_text'])\n",
    "#     X_train_pad = pad_sequences(X_train_embed_2, dtype='float32', padding='post', maxlen=200)\n",
    "#     return X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957a453-3287-4a59-92a3-5440f951dfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_text = preprocess_pad(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a9902-113f-4886-9ad6-84482e9d2005",
   "metadata": {},
   "source": [
    "# Functional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f27d34-2f01-4b2c-87f0-f5eadfee312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, callbacks, Model\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    # CNN Architecture\n",
    "    cnn_input = layers.Input(shape=X_image.shape[1:])\n",
    "\n",
    "    x = layers.Conv2D(16, (4, 4), activation='relu')(cnn_input)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(16, (4, 4), activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv2D(16, (4, 4), activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    cnn_output = layers.Flatten()(x)\n",
    "    \n",
    "    # LSTM Architecture\n",
    "    nlp_input =layers.Input(shape=(200,100))\n",
    "    y = layers.Masking()(nlp_input)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    y = layers.Bidirectional(layers.LSTM(32, activation='tanh', return_sequences=True))(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "\n",
    "    y = layers.Bidirectional(layers.LSTM(32, activation='tanh', return_sequences=True))(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "\n",
    "    y = layers.Bidirectional(layers.LSTM(32, activation='tanh', return_sequences=False))(y)\n",
    "    nlp_output = layers.Dropout(0.5)(y)\n",
    "    \n",
    "    # Define NLP model and concatenate output\n",
    "    combined = layers.concatenate([cnn_output, nlp_output])\n",
    "    \n",
    "    z = layers.Dense(64, activation='relu')(combined)\n",
    "    z = layers.Dropout(0.4)(z)\n",
    "    z = layers.Dense(32, activation='relu')(z)\n",
    "    z = layers.Dropout(0.2)(z)\n",
    "    \n",
    "    final_output = layers.Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, nlp_input],outputs=final_output)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f1235-7804-4904-b505-f304885a54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfaaf7d-eb4a-4171-b9d9-f79f6e9a83aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678cd2e-b921-47a7-96a5-5aec3a4d7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    (X_image, X_text_pad),\n",
    "    y,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    validation_split=0.3,\n",
    "    callbacks=callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be82d33-9c92-44fe-9d64-1d53bd052797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
