{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/sample_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e59171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords \n",
    "# import string\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(text):\n",
    "#     for punctuation in string.punctuation:\n",
    "#         text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "#     lowercased = text.lower() # Lower Case\n",
    "#     #tokenized = word_tokenize(lowercased) # Tokenize\n",
    "#     #words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "#     #stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "#     #without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "#     # lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "#     # lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "#     return lowercased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd202839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['clean_text'] = df['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['target']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c493cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df['text']\n",
    "# y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import Word2Vec\n",
    "\n",
    "#word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=10, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4315b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import numpy as np\n",
    "\n",
    "# # Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "# def embed_sentence(word2vec, sentence):\n",
    "#     embedded_sentence = []\n",
    "#     for word in sentence:\n",
    "#         if word in word2vec.wv:\n",
    "#             embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "#     return np.array(embedded_sentence)\n",
    "\n",
    "# # Function that converts a list of sentences into a list of matrices\n",
    "# def embedding(word2vec, sentences):\n",
    "#     embed = []\n",
    "    \n",
    "#     for sentence in sentences:\n",
    "#         embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "#         embed.append(embedded_sentence)\n",
    "        \n",
    "#     return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the training and test embedded sentences\n",
    "# X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "# X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678400b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# def init_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(layers.Masking())\n",
    "#     model.add(layers.LSTM(20, activation='tanh'))\n",
    "#     model.add(layers.Dense(15, activation='relu'))\n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='rmsprop',\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ec5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# model.fit(X_train_pad, y_train, \n",
    "#           batch_size = 32,\n",
    "#           epochs=100,\n",
    "#           validation_split=0.3,\n",
    "#           callbacks=[es]\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de46358",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate model \n",
    "\n",
    "#res = model.evaluate(X_test_pad, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be934088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34392abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e695e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258987c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b731aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935871f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c6d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947fb07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
